{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t9dFj3qTdDxc",
    "outputId": "09e65066-6f38-4613-9b13-ca8bee8ae75e",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\astan\\anaconda3\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorflow) (0.23.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorflow) (1.18.5)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.4)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.2)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorflow) (1.43.0)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorflow) (13.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (49.2.0.post20200714)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in c:\\users\\astan\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.10.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (5.0.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in c:\\users\\astan\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: tensorflow-text in c:\\users\\astan\\anaconda3\\lib\\site-packages (2.7.3)\n",
      "Requirement already satisfied: tensorflow-hub>=0.8.0 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorflow-text) (0.12.0)\n",
      "Requirement already satisfied: tensorflow<2.8,>=2.7.0 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorflow-text) (2.7.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorflow-hub>=0.8.0->tensorflow-text) (1.18.5)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorflow-hub>=0.8.0->tensorflow-text) (3.19.4)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (0.23.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (2.0)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (3.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (1.11.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (2.10.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (1.0.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (2.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (3.7.4.2)\n",
      "Requirement already satisfied: tensorboard~=2.6 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (2.8.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (1.1.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (1.43.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (13.0.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (0.34.2)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (2.7.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (1.1.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (3.3.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (2.24.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (1.0.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (49.2.0.post20200714)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (2.5.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in c:\\users\\astan\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (4.10.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (1.25.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (1.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in c:\\users\\astan\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (5.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (3.1.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (3.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\astan\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install tensorflow-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ZK8wnz42dFWr"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ifSQggdqdI6T",
    "outputId": "8ca96307-d8c4-4c6c-9db6-8af05b42e23a"
   },
   "outputs": [],
   "source": [
    "df=pd.read_excel('SMSSpamCollection.xlsx')\n",
    "df = df.dropna(how = \"any\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OQKmWo0RdK1j",
    "outputId": "ff3564b2-34dc-4c2b-b59e-3ca97cfe2f25"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4826\n",
       "spam     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = ['label', 'body']\n",
    "\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lxpj8R-aekgl"
   },
   "source": [
    "We have 747 spam emails and 4826 ham emails. The ham messages are significantly higher, implying that 15% are spam emails and 85% of ham emails, indicating an imbalance, so in order to balance the two classes, we reduce number of ham messages to 747."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQCHns3venbk"
   },
   "source": [
    "First, I create two data frames, one for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "l7OalHHbewaT"
   },
   "outputs": [],
   "source": [
    "df_spam = df[df['label']=='spam']\n",
    "df_ham = df[df['label']=='ham']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "VxRD9dnVfDSb"
   },
   "outputs": [],
   "source": [
    "df_ham_balanced = df_ham.sample(df_spam.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "PuyWsHlFfX5E"
   },
   "outputs": [],
   "source": [
    "df_balanced = pd.concat([df_ham_balanced, df_spam])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7T7pQXNofesc",
    "outputId": "df91cb63-43af-4dfc-b74f-2f527b8a352c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     747\n",
       "spam    747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7rKJbvI8f5sj"
   },
   "source": [
    "Now the dataset is balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6G-pBVDBgAgz"
   },
   "source": [
    "After balancing the data, we create another label representing if a message is spam (if it is 1) or ham (0). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "7zVfryHaf5FD"
   },
   "outputs": [],
   "source": [
    "df_balanced['spam'] = df_balanced['label'].apply(lambda x: 1 if x=='spam' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "6yevVwaygJcD",
    "outputId": "6e9ce598-fb21-49d8-abd9-fdaeb9c630a1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>body</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>spam</td>\n",
       "      <td>New TEXTBUDDY Chat 2 horny guys in ur area 4 j...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ãœ v ma fan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free Top ringtone -sub to weekly ringtone-get ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pls confirm the time to collect the cheque.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok. No wahala. Just remember that a friend in ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               body  spam\n",
       "628   spam  New TEXTBUDDY Chat 2 horny guys in ur area 4 j...     1\n",
       "1664   ham                                     Ãœ v ma fan...     0\n",
       "1687  spam  Free Top ringtone -sub to weekly ringtone-get ...     1\n",
       "1595   ham        Pls confirm the time to collect the cheque.     0\n",
       "1263   ham  Ok. No wahala. Just remember that a friend in ...     0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Tzdibf6g780"
   },
   "source": [
    "We will download two BERT models, one to perform preprocessing and the other one for encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "88wGRFeNg5zp"
   },
   "outputs": [],
   "source": [
    "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
    "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PiXLW5oDhAAc"
   },
   "source": [
    "We are going to use preprocess as the input for this layer. Then, the encoder is going to convert the preprocessed text in vectors (output of the layer). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "4-gWslighB6k"
   },
   "outputs": [],
   "source": [
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "preprocessed_text = bert_preprocess(text_input)\n",
    "outputs = bert_encoder(preprocessed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lx3nqpMyhUxz"
   },
   "source": [
    "Finally, this output is going to be fed in the neural network layers, that are two, the Dropout layer, and the Dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "AG5-9vQGhYFT"
   },
   "outputs": [],
   "source": [
    "layer = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n",
    "layer = tf.keras.layers.Dense(1, activation='sigmoid', name=\"output\")(layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QWPQib32heKr"
   },
   "source": [
    "We add the input and output layers to construct the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "cgBmJX7PhfbT"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=[text_input], outputs = [layer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uFg7JZGEhiok"
   },
   "source": [
    "Then we include a model summary to see all the input and output layers that are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IWsVGCX6hjv0",
    "outputId": "00966984-9955-4a11-94f4-595780b4c0d2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " text (InputLayer)              [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " keras_layer (KerasLayer)       {'input_mask': (Non  0           ['text[0][0]']                   \n",
      "                                e, 128),                                                          \n",
      "                                 'input_word_ids':                                                \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_type_ids':                                                \n",
      "                                (None, 128)}                                                      \n",
      "                                                                                                  \n",
      " keras_layer_1 (KerasLayer)     {'encoder_outputs':  109482241   ['keras_layer[0][0]',            \n",
      "                                 [(None, 128, 768),               'keras_layer[0][1]',            \n",
      "                                 (None, 128, 768),                'keras_layer[0][2]']            \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768)],                                               \n",
      "                                 'default': (None,                                                \n",
      "                                768),                                                             \n",
      "                                 'pooled_output': (                                               \n",
      "                                None, 768),                                                       \n",
      "                                 'sequence_output':                                               \n",
      "                                 (None, 128, 768)}                                                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 768)          0           ['keras_layer_1[0][13]']         \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1)            769         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,483,010\n",
      "Trainable params: 769\n",
      "Non-trainable params: 109,482,241\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VqmJALaYhs_U"
   },
   "source": [
    "We are going to compile the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "I53Y_H0_hwN8"
   },
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "metrics =  tf.keras.metrics.BinaryAccuracy(name='accuracy')\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    " loss=loss,\n",
    " metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9HhKznq7h4vr"
   },
   "source": [
    "Then we are going to fit the model. The model is going to learn from the samples of the training data, and identify patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UMX9NBiyh6rb",
    "outputId": "9511dab6-48f0-4583-e6df-261095c928b6",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "35/35 [==============================] - 187s 5s/step - loss: 0.5965 - accuracy: 0.7214\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - 218s 6s/step - loss: 0.4863 - accuracy: 0.8170\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - 244s 7s/step - loss: 0.4209 - accuracy: 0.8589\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - 228s 7s/step - loss: 0.3780 - accuracy: 0.8687\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - 233s 7s/step - loss: 0.3421 - accuracy: 0.8902\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - 228s 7s/step - loss: 0.3192 - accuracy: 0.8938\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - 231s 7s/step - loss: 0.3089 - accuracy: 0.9027\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - 242s 7s/step - loss: 0.2848 - accuracy: 0.9089\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - 230s 7s/step - loss: 0.2736 - accuracy: 0.9098\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - 225s 6s/step - loss: 0.2638 - accuracy: 0.9134\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x277a5375160>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_balanced['body'],df_balanced['spam'], stratify=df_balanced['spam'])\n",
    "model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kzi07MpY6Iwj"
   },
   "source": [
    "After training the model, we are going to predict and classify the samples in the testing dataset. We are going to get as an output an array of 0´s and 1´s, in which a 0 indicates that the message is ham and 1 if it is spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "cCFiWsxD6SYC"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = y_pred.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "srIhlbDt7aFq",
    "outputId": "a09ce2a1-2662-4964-e7f2-74057d91f80e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.where(y_pred > 0.5, 1, 0)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hCqkpoqJ7lZC"
   },
   "source": [
    "Also, we can make predictions inserting ourselves a set of messages, obtaining as a result an array of numbers, in which a number above 0.5 indicated that the message is considered spam, and a number below 0.5 that is ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "YXrwQZHk7qXS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.69952023],\n",
       "       [0.9169347 ],\n",
       "       [0.5298996 ],\n",
       "       [0.71341854],\n",
       "       [0.15887296]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_dataset = [\n",
    " 'You can win a lot of money, register in the link below',\n",
    " 'You have an iPhone 10, spin the image below to claim your prize and it will be delivered in your door step',\n",
    " 'You have an offer, the company will give you 50% off on every item purchased.',\n",
    " 'Hey Bravin, do not be late for the meeting tomorrow will start lot exactly 10:30 am',\n",
    " \"See you monday, we have alot to talk about the future of this company .\"\n",
    "]\n",
    "\n",
    "model.predict(sample_dataset)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NLP Spam",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
